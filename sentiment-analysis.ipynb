{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries for data handling and preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data if not already available\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the IMDB dataset from a local CSV file\n",
    "df = pd.read_csv(\"archive/IMDB Dataset.csv\")\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(\"Dataset loaded successfully!\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. <br /><br />The...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                      cleaned_review sentiment  \n",
       "0  one reviewers mentioned watching oz episode yo...  positive  \n",
       "1  wonderful little production filming technique ...  positive  \n",
       "2  thought wonderful way spend time hot summer we...  positive  \n",
       "3  basically theres family little boy jake thinks...  negative  \n",
       "4  petter matteis love time money visually stunni...  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure the necessary NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove non-alphabetic characters (keeping spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Assuming df is your DataFrame and it has the 'review' column\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Show the cleaned data\n",
    "print(\"Preprocessing completed!\")\n",
    "df[['review', 'cleaned_review', 'sentiment']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review sentiment  \n",
      "0  one reviewers mentioned watching oz episode yo...  positive  \n",
      "1  wonderful little production filming technique ...  positive  \n",
      "2  thought wonderful way spend time hot summer we...  positive  \n",
      "3  basically theres family little boy jake thinks...  negative  \n",
      "4  petter matteis love time money visually stunni...  positive  \n"
     ]
    }
   ],
   "source": [
    "# Show the cleaned data\n",
    "print(df[['review', 'cleaned_review', 'sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86      4961\n",
      "    positive       0.87      0.85      0.86      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Predicted sentiment using Naive Bayes: negative\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure the necessary NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove non-alphabetic characters (keeping spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Assuming df is your DataFrame and it has the 'review' column\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Let's train a model (we'll use Naive Bayes here)\n",
    "X = df['cleaned_review']  # Input feature (text data)\n",
    "y = df['sentiment']  # Target label (sentiment)\n",
    "\n",
    "# Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=50000, stop_words='english')  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Use the trained model to predict on test data\n",
    "y_pred_nb = model_nb.predict(X_test_tfidf)\n",
    "\n",
    "# Display classification report for Naive Bayes\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Define a function to classify a review using the trained Naive Bayes model\n",
    "def classify_naive_bayes(review):\n",
    "    # Preprocess the review\n",
    "    review_cleaned = preprocess_text(review)\n",
    "    \n",
    "    # Vectorize the review\n",
    "    review_tfidf = vectorizer.transform([review_cleaned])\n",
    "    \n",
    "    # Predict sentiment using Naive Bayes\n",
    "    return model_nb.predict(review_tfidf)[0]\n",
    "\n",
    "# Example usage: Get sentiment of a new review\n",
    "new_review = input(\"Enter the review for sentiment analysis: \")\n",
    "sentiment_nb = classify_naive_bayes(new_review)\n",
    "print(f\"Predicted sentiment using Naive Bayes: {sentiment_nb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have already trained the model and vectorizer\n",
    "# Save the Naive Bayes model to a file\n",
    "joblib.dump(model_nb, 'naive_bayes_model.pkl')\n",
    "\n",
    "# Save the vectorizer to a file\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Model and vectorizer saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the vectorizer and Naive Bayes model already trained\n",
    "# Preprocess and vectorize the input text\n",
    "def preprocess_text(text):\n",
    "    # Add your preprocessing steps here\n",
    "    return text.lower()\n",
    "\n",
    "def classify_with_threshold(review, model, vectorizer, threshold=0.2):\n",
    "    # Preprocess the review\n",
    "    review_cleaned = preprocess_text(review)\n",
    "    \n",
    "    # Vectorize the review\n",
    "    review_tfidf = vectorizer.transform([review_cleaned])\n",
    "    \n",
    "    # Predict probabilities for positive and negative sentiment\n",
    "    prob = model.predict_proba(review_tfidf)[0]  # Getting probabilities for each class\n",
    "    \n",
    "    positive_prob = prob[1]  # Probability for positive sentiment\n",
    "    negative_prob = prob[0]  # Probability for negative sentiment\n",
    "    \n",
    "    # If the probabilities are too close to each other, classify as neutral\n",
    "    if abs(positive_prob - negative_prob) < threshold:\n",
    "        return 'neutral'\n",
    "    elif positive_prob > negative_prob:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Example usage: Get sentiment of a new review\n",
    "new_review = input(\"Enter the review for sentiment analysis: \")\n",
    "\n",
    "# Load saved model and vectorizer\n",
    "loaded_model = joblib.load('naive_bayes_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Classify review\n",
    "sentiment = classify_with_threshold(new_review, loaded_model, loaded_vectorizer)\n",
    "print(f\"Predicted sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data paths: ['C:\\\\Users\\\\yohan/nltk_data', 'c:\\\\Python312\\\\nltk_data', 'c:\\\\Python312\\\\share\\\\nltk_data', 'c:\\\\Python312\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\yohan\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'C:\\\\nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed!\n",
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review sentiment  \n",
      "0  one review mention watch oz episod hook right ...  positive  \n",
      "1  wonder littl product film techniqu fashion giv...  positive  \n",
      "2  thought wonder way spend time hot summer weeke...  positive  \n",
      "3  basic famili littl boy jake think zombi closet...  negative  \n",
      "4  petter mattei love time money visual stun film...  positive  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "# Set the path explicitly for NLTK data\n",
    "nltk.data.path.append('C:\\\\nltk_data')\n",
    "\n",
    "# Print current NLTK data paths to verify if the path was added\n",
    "print(\"NLTK data paths:\", nltk.data.path)\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords', download_dir='C:\\\\nltk_data')\n",
    "nltk.download('punkt', download_dir='C:\\\\nltk_data')\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())  # Convert to lowercase for consistency\n",
    "\n",
    "    # Remove stopwords and apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words and word.isalpha()]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Assuming df is your DataFrame and it has the 'review' column\n",
    "# Apply preprocessing to the reviews\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Show the cleaned data\n",
    "print(\"Preprocessing completed!\")\n",
    "print(df[['review', 'cleaned_review', 'sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "classify_with_threshold() missing 2 required positional arguments: 'model' and 'vectorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m new_review \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the review for sentiment analysis: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Classify the sentiment\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_with_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_review\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted sentiment:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sentiment)\n",
      "\u001b[1;31mTypeError\u001b[0m: classify_with_threshold() missing 2 required positional arguments: 'model' and 'vectorizer'"
     ]
    }
   ],
   "source": [
    "# Take input from the user\n",
    "new_review = input(\"Enter the review for sentiment analysis: \")\n",
    "\n",
    "# Classify the sentiment\n",
    "sentiment = classify_with_threshold(new_review)\n",
    "print(\"Predicted sentiment:\", sentiment)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
